{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Math Application with promptulate Agents\n",
    "This demo is how to use promptulates agents to create a custom Math application utilising OpenAI's GPT3.5 Model.\n",
    "For the application frontend, there will be using streamlit, an easy-to-use open-source Python framework. \n",
    "This generative math application, let’s call it “Math Wiz”, is designed to help users with their math or reasoning/logic questions.\n",
    "\n",
    "## Reference reading\n",
    "[Building a Math Application with LangChain Agents](https://towardsdatascience.com/building-a-math-application-with-langchain-agents-23919d09a4d3)\n",
    "\n",
    "the app schema for “Math Wiz” looks like the following:\n",
    "![App-Schema-for-Math-Wiz diagram](./img/App-Schema-for-Math-Wiz.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7207979682ff90d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Setup\n",
    "We can start off by creating a new conda environment with python=3.11:`conda create -n math_assistant python=3.11`\n",
    "\n",
    "Activate the environment:`conda activate math_assistant`\n",
    "\n",
    "Next, let’s install all necessary libraries:\n",
    "`pip install -U promptulate` \n",
    "`pip install wikipedia`\n",
    "`pip install numexpr`\n",
    "\n",
    "Sign up at OpenAI and obtain your own key to start making calls to the gpt model. Once you have the key, create a .env file in your repository and store the OpenAI key:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c14bd58db4084624"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"your_openai_api_key\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T18:16:10.106921200Z",
     "start_time": "2024-04-15T18:16:10.050771300Z"
    }
   },
   "id": "bdba0ee6cdddfda1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Application Flow\n",
    "The application flow for Math Wiz is outlined in the flowchart below. The agent in our pipeline will have a set of tools at its disposal that it can use to answer a user query. The Large Language Model (LLM) serves as the “brain” of the agent, guiding its decisions. When a user submits a question, the agent uses the LLM to select the most appropriate tool or a combination of tools to provide an answer. If the agent determines it needs multiple tools, it will also specify the order in which the tools are used.\n",
    "![Promptulate-Agents-Deconstructed](./img/Promptulate-Agents-Deconstructed.png)\n",
    "\n",
    "**The application flow for Math Wiz is outlined below:**\n",
    "\n",
    "The agent in our pipeline will have a set of tools at its disposal that it can use to answer a user query. The Large Language Model (LLM) serves as the “brain” of the agent, guiding its decisions. When a user submits a question, the agent uses the LLM to select the most appropriate tool or a combination of tools to provide an answer. If the agent determines it needs multiple tools, it will also specify the order in which the tools are used.\n",
    "\n",
    "The agent for our Math Wiz app will be using the following tools:\n",
    "\n",
    "1. **Wikipedia Tool:** this tool will be responsible for fetching the latest information from Wikipedia using the Wikipedia API. While there are paid tools and APIs available that can be integrated inside LangChain, I would be using Wikipedia as the app’s online source of information.\n",
    "\n",
    "2. **Calculator Tool:** this tool would be responsible for solving a user’s math queries. This includes anything involving numerical calculations. For example, if a user asks what the square root of 4 is, this tool would be appropriate.\n",
    "\n",
    "3. **Reasoning Tool:** the final tool in our application setup would be a reasoning tool, responsible for tackling logical/reasoning-based user queries. Any mathematical word problems should also be handled with this tool.\n",
    "\n",
    "Now that we have a rough application design, we can begin thinking about building this application."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57d30c50ed555e46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding promptulate Agents\n",
    "\n",
    "Promptulate agents are designed to enhance interaction with language models by providing an interface for more complex and interactive tasks. We can think of an agent as an intermediary between users and a large language model. Agents seek to break down a seemingly complex user query, that our LLM might not be able to tackle on its own, into easier, actionable steps.\n",
    "\n",
    "In our application flow, we defined a few different tools that we would like to use for our math application. Based on the user input, the agent should decide which of these tools to use. If a tool is not required, it should not be used. Promptulate agents can simplify this for us. These agents use a language model to choose a sequence of actions to take. Essentially, the LLM acts as the “brain” of the agent, guiding it on which tool to use for a particular query, and in which order. This is different from Proptulate chains where the sequence of actions are hardcoded in code. Promptulate offers a wide set of tools that can be integrated with an agent. These tools include, and are not limited to, online search tools, API-based tools, chain-based tools etc. For more information on Promptulate agents and their types, see [this](https://undertone0809.github.io/promptulate/#/modules/agent?id=agent)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eac444b133599049"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step-by-Step Implementation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "580a0bd570fd6545"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1\n",
    "\n",
    "Create a `chatbot.py` script and import the necessary dependencies:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22e6af33468bbed4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from promptulate.llms import ChatOpenAI\n",
    "from promptulate.tools.wikipedia.tools import wikipedia_search\n",
    "from promptulate.tools.math.tools import calculator\n",
    "from promptulate.schema import MessageSet, SystemMessage, UserMessage, AssistantMessage\n",
    "import promptulate as pne"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T18:16:10.116650900Z",
     "start_time": "2024-04-15T18:16:10.070083Z"
    }
   },
   "id": "bf24915502504abb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2\n",
    "Next, we will define our OpenAI-based Language Model.The architectural design of `promptulate` is easily compatible with different large language model extensions. In `promptulate`, llm is responsible for the most basic part of content generation, so it is the most basic component.By default, `ChatOpenAI` in `promptulate` uses the `gpt-3.5-turbo` model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24cf6e82bd6c908e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T18:16:10.116650900Z",
     "start_time": "2024-04-15T18:16:10.085734700Z"
    }
   },
   "id": "ca8d4ef8b9b9bcc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We would be using this LLM both within our math and reasoning process and as the decision maker for our agent."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "479c360af07d9a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3\n",
    "When constructing your own agent, you will need to provide it with a list of tools that it can use. Difine a tool， the only you need to do is to provide a function to Promptulate. Promptulate will automatically convert it to a tool that can be used by the language learning model (LLM). The final presentation result it presents to LLM is an OpenAI type JSON schema declaration.\n",
    "\n",
    "Actually, Promptulate will analysis function name, parameters type, parameters attribution, annotations and docs when you provide the function. We strongly recommend that you use the official best practices of Template for function writing. The best implementation of a function requires adding type declarations to its parameters and providing function level annotations. Ideally, declare the meaning of each parameter within the annotations.\n",
    "\n",
    "We will now create our three tools. The first one will be the online tool using the Wikipedia API wrapper:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2b9b2c90ec135c6"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Wikipedia Tool\n",
    "def wikipedia_tool(keyword: str) -> str:\n",
    "    \"\"\"search by keyword in web.\n",
    "        description:\n",
    "            A useful tool for searching the Internet to find information on world events, issues, dates,years, etc.\n",
    "            Worth using for general topics. Use precise questions.\n",
    "\n",
    "        Args:\n",
    "            keyword: keyword to search\n",
    "\n",
    "        Returns:\n",
    "            str: search result\n",
    "        \"\"\"\n",
    "    return wikipedia_search(keyword)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T18:16:10.118103600Z",
     "start_time": "2024-04-15T18:16:10.099888900Z"
    }
   },
   "id": "2432245bfeb3ec83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let’s define the tool that we will be using for calculating any numerical expressions. `Promptulate` offers the `calculator` which uses the `numexpr` Python library to calculate mathematical expressions. It is also important that we clearly define what this tool would be used for. The description can be helpful for the agent in deciding which tool to use from a set of tools for a particular user query. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd71e0b1f2e2b3ba"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# calculator tool for arithmetics\n",
    "def math_tool(expression):\n",
    "    \"\"\"\n",
    "        description:\n",
    "            Useful for when you need to answer numeric questions.\n",
    "            Your input is a nature language of math expression. Attention: Expressions can not exist variables!\n",
    "            eg: (current age)^0.43 is wrong, you should use 18^0.43 instead.\n",
    "    \"\"\"\n",
    "    return calculator(expression)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T18:16:10.140785400Z",
     "start_time": "2024-04-15T18:16:10.116650900Z"
    }
   },
   "id": "f34cd4480745694b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we will be defining the tool for logic/reasoning-based queries. We will first create a prompt to instruct the model with executing the specific task. Then we will create a simple `AssistantMessage` for this tool, passing it the LLM and the prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ffdb61331ee9735"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "WORD_PROBLEM_TEMPLATE = \"\"\"You are a reasoning agent tasked with solving t he user's logic-based questions. \n",
    "                            Logically arrive at the solution, and be factual. \n",
    "                            In your answers, clearly detail the steps involved and give the final answer. \n",
    "                            Provide the response in bullet points. Question  {question} Answer\"\"\"\n",
    "user_question = input(\"Enter your question: \")\n",
    "formatted_template = WORD_PROBLEM_TEMPLATE.format(question=user_question)\n",
    "\n",
    "# prompt for reasoning based tool\n",
    "# math_assistant_prompt = StringTemplate(WORD_PROBLEM_TEMPLATE, template_format=\"jinja2\")\n",
    "messages = MessageSet(\n",
    "    messages=[\n",
    "        SystemMessage(content=formatted_template),\n",
    "        UserMessage(content=user_question)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# reasoning based tool\n",
    "def word_problem_tool():\n",
    "    \"\"\"\n",
    "        description:\n",
    "        Useful for when you need to answer logic-based/reasoning questions.\n",
    "    \"\"\"\n",
    "    response: AssistantMessage = llm.predict(messages)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T18:16:13.155160200Z",
     "start_time": "2024-04-15T18:16:10.133683300Z"
    }
   },
   "id": "9e135028cb2f3b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4\n",
    "We will now initialize our agent with the tools we have created above. We will also specify the LLM to help it choose which tools to use and in what order:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0dec33956572b1a"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31;1m\u001B[1;3m[Agent] Tool Agent start...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m[User instruction] I have 3 apples and 4 oranges.I give half of my oranges away and buy two dozen new ones,along with three packs of strawberries.Each pack of strawberry has 30 strawberries.How many total pieces of fruit do I have at the end?\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Thought] Calculate the total number of fruits after the given scenario.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Action] calculator args: {'expression': '(3 + 4/2 + 24 + 3*30)'}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Observation] 119.0\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Thought] To ensure accuracy and address the user's query comprehensively.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Action] calculator args: {'expression': '119'}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Observation] 119\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Thought] Considering the complexity of the task, a breakdown of the different types of fruits could be helpful to calculate the total accurately.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Action] calculator args: {'expression': '3 + 4/2 + 24 + 3*30'}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Observation] 119.0\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Thought] To provide a more detailed breakdown of the fruit count and ensure accuracy in the calculation.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Action] calculator args: {'expression': '(3 + 24) + (4/2) + (3*30)'}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Observation] 119.0\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Thought] To provide a detailed breakdown and accurate calculation of the total number of each type of fruit after the scenario.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Action] calculator args: {'expression': '3 + 24 + 2*12 + 3*30'}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Observation] 141\u001B[0m\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 8 column 5 (char 312)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# agent\u001B[39;00m\n\u001B[0;32m      2\u001B[0m agent \u001B[38;5;241m=\u001B[39m pne\u001B[38;5;241m.\u001B[39mToolAgent(tools\u001B[38;5;241m=\u001B[39m[wikipedia_search, calculator, word_problem_tool],\n\u001B[0;32m      3\u001B[0m                       llm\u001B[38;5;241m=\u001B[39mllm)\n\u001B[1;32m----> 5\u001B[0m resp: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_question\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(resp)\n",
      "File \u001B[1;32mD:\\Projects\\LLM\\promptulate\\promptulate\\agents\\base.py:43\u001B[0m, in \u001B[0;36mBaseAgent.run\u001B[1;34m(self, instruction, output_schema, examples, *args, **kwargs)\u001B[0m\n\u001B[0;32m     32\u001B[0m Hook\u001B[38;5;241m.\u001B[39mcall_hook(\n\u001B[0;32m     33\u001B[0m     HookTable\u001B[38;5;241m.\u001B[39mON_AGENT_START,\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     40\u001B[0m )\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# get original response from LLM\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m result: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run(instruction, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Return Pydantic instance if output_schema is specified\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_schema:\n",
      "File \u001B[1;32mD:\\Projects\\LLM\\promptulate\\promptulate\\agents\\tool_agent\\agent.py:149\u001B[0m, in \u001B[0;36mToolAgent._run\u001B[1;34m(self, instruction, return_raw_data, **kwargs)\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m llm_resp \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    145\u001B[0m     llm_resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm(\n\u001B[0;32m    146\u001B[0m         instruction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconversation_prompt \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_date\n\u001B[0;32m    147\u001B[0m     )\n\u001B[1;32m--> 149\u001B[0m action_resp: ActionResponse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_llm_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mllm_resp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconversation_prompt \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mllm_resp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    151\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[pne] tool agent <\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miterations\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m> current prompt: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconversation_prompt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m    153\u001B[0m )\n",
      "File \u001B[1;32mD:\\Projects\\LLM\\promptulate\\promptulate\\agents\\tool_agent\\agent.py:211\u001B[0m, in \u001B[0;36mToolAgent._parse_llm_response\u001B[1;34m(self, llm_resp)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Parse next instruction of LLM output.\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \n\u001B[0;32m    200\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m    action_input(dict | str): tool parameters\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    208\u001B[0m llm_resp: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    209\u001B[0m     llm_resp\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m```json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m```JSON\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m```\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    210\u001B[0m )\n\u001B[1;32m--> 211\u001B[0m data: \u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mllm_resp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ActionResponse(\n\u001B[0;32m    214\u001B[0m     thought\u001B[38;5;241m=\u001B[39mdata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthought\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    215\u001B[0m     action_name\u001B[38;5;241m=\u001B[39mdata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maction\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    216\u001B[0m     action_parameters\u001B[38;5;241m=\u001B[39mdata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maction\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    217\u001B[0m )\n",
      "File \u001B[1;32mD:\\SoftwareInstallation\\Conda\\envs\\promptulate\\lib\\json\\__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[1;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[1;32mD:\\SoftwareInstallation\\Conda\\envs\\promptulate\\lib\\json\\decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[1;34m(self, s, _w)\u001B[0m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[0;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[0;32m    335\u001B[0m \n\u001B[0;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[1;32mD:\\SoftwareInstallation\\Conda\\envs\\promptulate\\lib\\json\\decoder.py:353\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[1;34m(self, s, idx)\u001B[0m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    350\u001B[0m \n\u001B[0;32m    351\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mJSONDecodeError\u001B[0m: Expecting property name enclosed in double quotes: line 8 column 5 (char 312)"
     ]
    }
   ],
   "source": [
    "# agent\n",
    "agent = pne.ToolAgent(tools=[wikipedia_tool, math_tool, word_problem_tool],\n",
    "                      llm=llm)\n",
    "\n",
    "resp: str = agent.run(user_question)\n",
    "print(resp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T18:16:28.650409200Z",
     "start_time": "2024-04-15T18:16:13.131331800Z"
    }
   },
   "id": "5b03977f863172b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The app’s response to a logic question is following:**\n",
    "![test-question-answer](./img/test-question-answer.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f03211a6b5fdb861"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-15T18:16:28.649414900Z"
    }
   },
   "id": "d4d460ea404ecca7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
