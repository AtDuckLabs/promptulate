{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Custom LLM\n",
    "This guide details the process of creating a custom Language Model (LLM) wrapper for use with Promptulate. To integrate your own LLM or an alternative to the supported wrappers, your custom LLM class must implement two essential methods.\n",
    "\n",
    "Below is a template for a custom LLM class:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1119748334dd18c4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from promptulate.llms.base import BaseLLM\n",
    "from promptulate.schema import MessageSet, AssistantMessage\n",
    "\n",
    "\n",
    "class MyLLM(BaseLLM):\n",
    "    def _predict(self, messages: MessageSet, *args, **kwargs) -> AssistantMessage:\n",
    "        return AssistantMessage(content=\"This is predict reply\")\n",
    "\n",
    "    def __call__(self, instruction: str, *args, **kwargs):\n",
    "        return \"This is call reply\""
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T19:18:44.548937700Z",
     "start_time": "2024-01-10T19:18:44.534934700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Your Custom LLM\n",
    "\n",
    "You can interact with your custom LLM in two ways:\n",
    "\n",
    "1. Using the __call__ Method:\n",
    "This allows you to invoke your LLM as if it were a function:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5b1045e297203"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is call reply\n"
     ]
    }
   ],
   "source": [
    "llm = MyLLM()\n",
    "resp: str = llm(\"How is everything going?\")\n",
    "print(resp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T19:18:45.617951300Z",
     "start_time": "2024-01-10T19:18:45.597951200Z"
    }
   },
   "id": "116ab585029d1f87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Using the `predict` Method:\n",
    "\n",
    "This method is used to get a structured response from your LLM:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea5a58c12a12f2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is predict reply\n"
     ]
    }
   ],
   "source": [
    "from promptulate.schema import AssistantMessage, MessageSet, SystemMessage\n",
    "\n",
    "messages = MessageSet([\n",
    "    SystemMessage(content=\"You are a helpful assistant.\")\n",
    "])\n",
    "\n",
    "llm = MyLLM()\n",
    "resp_message: AssistantMessage = llm.predict(messages)\n",
    "print(resp_message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T19:18:46.832877500Z",
     "start_time": "2024-01-10T19:18:46.811876800Z"
    }
   },
   "id": "8b6de96f231641de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
